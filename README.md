# Interpretable-AI-Poster:Using Provably Optimal Sparse Tree Algorithms in Healthcare
## Introduction:
This repository contains the code and data associated with our research project titled "Interpretable AI: Using Provably Optimal Sparse Tree Algorithms in Healthcare." In this project, we explore the application of provably optimal sparse tree algorithms in healthcare to address the need for interpretable AI models.

## Research Objective:
Our primary objective is to demonstrate that interpretable AI models, specifically Optimal Sparse Regression Tree (OSRT) and General Optimal Sparse Decision Tree (GOSDT), can provide transparent and accurate predictions for key health metrics such as heart disease risk, anxiety diagnosis, and chronic condition prevalence.

## Methodology:
Data Preprocessing: We preprocess the datasets, including binarizing attributes and optimizing sample sizes.
Model Training: We train OSRT and GOSDT models using K-Fold validation techniques.
Model Evaluation: We evaluate the performance of the trained models and compare them with other algorithms such as CART, Random Forest, XGBoost, SVM, Perceptron, and Logistic Regression.

## Repository Structure:
Code: Contains Python scripts for data preprocessing, model training, and evaluation.
Data: Includes datasets used in the research, sourced from publicly available repositories.
Results: Provides summary reports and visualizations of the model performance.
References: Lists relevant literature and resources that informed our research.

## How to Use:
Clone the repository to your local machine.
Install the required dependencies specified in the requirements.txt file.
Run the Python scripts in the code directory to preprocess data, train models, and evaluate performance.
Explore the results and visualizations generated in the results directory.

## Contact Information:
For any inquiries or collaborations related to this research, please feel free to reach out to us:

### Mushran Khan (Email: mushranmahin@gmail.com)
### Caleb Rodriguez (Email: caleb.rodriguez@rutgers.edu)

## Acknowledgement:
We extend our gratitude to Rui Zhang, Cynthia Rudin and Linda Ness for their guidance and support throughout this research endeavor.
