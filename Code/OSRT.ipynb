{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"263929f6-ea30-49a4-86d2-7f4b5708720d\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_name = _hex_json.loads(\"\\\"OSRT\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_status = _hex_json.loads(\"\\\"\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_categories = _hex_json.loads(\"[]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"# Install osrt\n\nimport os\nos.environ[\"SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL\"] = \"True\"\n!pip install osrt\n\n# Install gosdt\n!pip install gosdt","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Collecting osrt\n  Downloading osrt-0.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: setuptools in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (68.2.2)\nRequirement already satisfied: wheel in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (0.38.4)\nRequirement already satisfied: attrs in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (23.1.0)\nRequirement already satisfied: packaging>=20.9 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (21.3)\nRequirement already satisfied: pandas in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (1.5.3)\nCollecting sklearn (from osrt)\n  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hRequirement already satisfied: sortedcontainers in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (2.4.0)\nCollecting gmpy2 (from osrt)\n  Downloading gmpy2-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: matplotlib in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from osrt) (3.8.3)\nCollecting editables==0.2 (from osrt)\n  Downloading editables-0.2-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from packaging>=20.9->osrt) (3.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (0.10.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (4.34.4)\nRequirement already satisfied: kiwisolver>=1.3.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (1.3.2)\nRequirement already satisfied: numpy<2,>=1.21 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (1.23.4)\nRequirement already satisfied: pillow>=8 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (9.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (2.8.2)\nRequirement already satisfied: importlib-resources>=3.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->osrt) (5.10.0)\nRequirement already satisfied: pytz>=2020.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from pandas->osrt) (2023.3.post1)\nRequirement already satisfied: six in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->osrt) (1.15.0)\nRequirement already satisfied: zipp>=3.1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->osrt) (3.10.0)\nDownloading osrt-0.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.1/516.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading editables-0.2-py3-none-any.whl (4.6 kB)\nDownloading gmpy2-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sklearn\n  Building wheel for sklearn (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0.post12-py3-none-any.whl size=2179 sha256=6c9b0d25352f10c76e2a59dc64e494f614fac41d48f88f08514bc1b483e28e19\n  Stored in directory: /home/hexuser/.cache/pip/wheels/2e/52/73/b1127c928e54b3d127adfb67b608d945d93a8ff571a4970535\nSuccessfully built sklearn\nInstalling collected packages: sklearn, gmpy2, editables, osrt\nSuccessfully installed editables-0.2 gmpy2-2.1.5 osrt-0.1.2 sklearn-0.0.post12\nCollecting gosdt\n  Downloading gosdt-0.1.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: setuptools in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (68.2.2)\nRequirement already satisfied: wheel in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (0.38.4)\nRequirement already satisfied: attrs in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (23.1.0)\nRequirement already satisfied: packaging>=20.9 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (21.3)\nRequirement already satisfied: pandas in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (1.5.3)\nRequirement already satisfied: scikit-learn in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (1.2.2)\nRequirement already satisfied: sortedcontainers in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (2.4.0)\nRequirement already satisfied: matplotlib in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (3.8.3)\nRequirement already satisfied: gmpy2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (2.1.5)\nRequirement already satisfied: editables==0.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from gosdt) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from packaging>=20.9->gosdt) (3.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (0.10.0)\nRequirement already satisfied: fonttools>=4.22.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (4.34.4)\nRequirement already satisfied: kiwisolver>=1.3.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (1.3.2)\nRequirement already satisfied: numpy<2,>=1.21 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (1.23.4)\nRequirement already satisfied: pillow>=8 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (9.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (2.8.2)\nRequirement already satisfied: importlib-resources>=3.2.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from matplotlib->gosdt) (5.10.0)\nRequirement already satisfied: pytz>=2020.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from pandas->gosdt) (2023.3.post1)\nRequirement already satisfied: scipy>=1.3.2 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from scikit-learn->gosdt) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from scikit-learn->gosdt) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from scikit-learn->gosdt) (3.0.0)\nRequirement already satisfied: six in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->gosdt) (1.15.0)\nRequirement already satisfied: zipp>=3.1.0 in /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->gosdt) (3.10.0)\nDownloading gosdt-0.1.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: gosdt\nSuccessfully installed gosdt-0.1.8\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import f_regression\n\n# Load the dataset\nfile_path = os.path.join(os.getcwd(), \"Medicaid_Conditions_Binarized.csv\")\ndf = pd.read_csv(file_path)\n\n# Prepare the data\nX = df.drop(\"target\", axis=1)\ny = df[\"target\"]\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Get the p-values for the features\n_, p_values = f_regression(X_train, y_train)\n\n# Get the significant variables\nsignificant_variables2 = X.columns[p_values < 0.05]\n\n# Create a new dataframe with only the significant variables\nsignificant_df = df[significant_variables2]\n\n# Output the significant_df to a csv file\noutput_csv_path = os.path.join(os.getcwd(), \"General_Disease_Significant.csv\")\nsignificant_df.to_csv(output_csv_path, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First attempt at fitting model\nimport pandas as pd\nimport numpy as np\nimport time\nimport pathlib\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, roc_auc_score, balanced_accuracy_score\n\n# Assuming compute_thresholds and OSRT are available in the current directory or a correct path.\nfrom osrt.model.threshold_guess import compute_thresholds\nfrom osrt.model.osrt import OSRT\nfrom gosdt.model.gosdt import GOSDT\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\n\n# read the dataset\n# preprocess your data otherwise OSRT will binarize continuous feature using all threshold values.\ndf = pd.read_csv(\"General_Disease_Significant.csv\")\nX, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\nh = df.columns[:-1]\nX = pd.DataFrame(X, columns=h)\n\n# guess thresholds (OPTIONAL) uncomment following lines if you want to speed up optimization\n# NOTE: You should also evaluate accuracy on guessed data if you choose to guess thresholds\n# GBRT parameters for threshold guesses\nn_est = 40\nmax_depth = 1\nX_opt, thresholds, header, threshold_guess_time = compute_thresholds(\n    X, y, n_est, max_depth\n)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_opt, y, test_size=0.2, random_state=42\n)\n\n# X_train = X\n# y_train = pd.DataFrame(y)\nprint(\"X_train:\", X_train.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_test:\", y_test.shape)\n\n# train OSRT model\n#config = {\n#    \"similar_support\": False,\n#    \"feature_exchange\": False,\n#    \"continuous_feature_exchange\": False,\n#    \"regularization\": 0.007,\n#    \"depth_budget\": 6,\n#    \"model_limit\": 1,\n#    \"time_limit\": 0,\n#    \"metric\": \"L2\",\n#    \"weights\": [],\n#    \"verbose\": False,\n#    \"diagnostics\": True,\n# }\n\nconfig = {\n    \"similar_support\": False,\n    \"regularization\": 0.01,\n}\n\n#model = GOSDT(config)\nmodel = OSRT(config)\n\nmodel.fit(X_train, y_train)\n\nprint(\"evaluate the model, extracting tree and scores\", flush=True)\n\n# get the results of trained model\ntrain_score = model.score(X_train, y_train)\nn_leaves = model.leaves()\nn_nodes = model.nodes()\ntime = model.time\ndepth = model.max_depth()\n\n\nprint(\"Model training time: {}\".format(time))\nprint(\"Training Score: {}\".format(train_score))\nprint(\"# of leaves: {}\".format(n_leaves))\nprint(\"Depth: {}\".format(depth))\nprint(model.tree)\n\n# Test model\ny_predict = model.predict(X_test)\ntest_mse = mean_squared_error(y_test, y_predict)\ntest_r2 = r2_score(y_test, y_predict)\n#acc_score = accuracy_score(y_test, y_predict)\n#bal_acc_score = balanced_accuracy_score(y_test, y_predict)\n#roc_score = roc_auc_score(y_test, y_predict)\nprint(\"Final MSE: {}\".format(test_mse))\nprint(\"Final R2: {}\".format(test_r2))\n#print(\"Accuracy Score: {}\".format(acc_score))\n#print(\"Balanced Accuracy Score: {}\".format(bal_acc_score))\n#print(\"ROC AUC Score: {}\".format(roc_score))","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"X_train: (23263, 6)\ny_train: (23263,)\nX_test: (5816, 6)\ny_test: (5816,)\nosrt reported successful execution\ntraining completed. 1.413 seconds.\nbounds: [0.309004..0.309004] (0.000000) normalized loss=0.239004, iterations=506\nevaluate the model, extracting tree and scores\nModel training time: 1.4129999876022339\nTraining Score: 0.005283407132066759\n# of leaves: 7\nDepth: 7\nif Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 = 1 and Diabetes<=0.5 = 1 and Hyperlipidemia<=0.5 = 1 and Hypertension<=0.5 = 1 and Ischemic Heart Disease<=0.5 = 1 then:\n    predicted class: 0.068312\n    normalized loss penalty: 0.141\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 = 1 and Diabetes<=0.5 = 1 and Hyperlipidemia<=0.5 = 1 and Hypertension<=0.5 = 1 and Ischemic Heart Disease<=0.5 != 1 then:\n    predicted class: 0.221716\n    normalized loss penalty: 0.012\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 = 1 and Diabetes<=0.5 = 1 and Hyperlipidemia<=0.5 = 1 and Hypertension<=0.5 != 1 then:\n    predicted class: 0.51067\n    normalized loss penalty: 0.028\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 = 1 and Diabetes<=0.5 = 1 and Hyperlipidemia<=0.5 != 1 then:\n    predicted class: 0.389631\n    normalized loss penalty: 0.028\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 = 1 and Diabetes<=0.5 != 1 then:\n    predicted class: 0.294213\n    normalized loss penalty: 0.011\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 = 1 and Chronic Kidney Disease<=0.5 != 1 then:\n    predicted class: 0.246613\n    normalized loss penalty: 0.007\n    complexity penalty: 0.01\n\nelse if Arthritis<=0.5 != 1 then:\n    predicted class: 0.291456\n    normalized loss penalty: 0.011\n    complexity penalty: 0.01\nFinal MSE: 0.005457980116535764\nFinal R2: 0.758820618054933\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# -----CART-----\nfrom math import sqrt\nimport time\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n\ndf = pd.read_csv(\"Medicaid_Conditions_Binarized.csv\")\nX, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\nh = df.columns[:-1]\nX = pd.DataFrame(X, columns=h)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# best_depth=6\n#cart_model = DecisionTreeClassifier(min_impurity_decrease=0.008)\ncart_model = DecisionTreeRegressor(min_impurity_decrease=0.001)\n\nstart_time = time.time()\ncart_model.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\ny_test_pred = cart_model.predict(X_test)\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nleaves = cart_model.get_n_leaves()\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\nbest_depth = cart_model.get_depth()\n\nprint(f\"-----CART-----\")\nprint(f\"Depth: {best_depth}\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"Number of Leaves: {leaves}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()\n\n\n# -----Random Forest-----\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Initialize the RandomForestClassifier with current depth_limit\n# best_depth=7\n#rf_clf = RandomForestClassifier(min_impurity_decrease=0.008, random_state=42)\nrf_clf = RandomForestRegressor(min_impurity_decrease=0.001,random_state=42)\n\nstart_time = time.time()\nrf_clf.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\n# Predict on the test set\ny_test_pred = rf_clf.predict(X_test)\n\n# Calculate the number of leaves\nnum_leaves = sum(tree.tree_.n_leaves for tree in rf_clf.estimators_)\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\nmax_depth = list()\nfor tree in rf_clf.estimators_:\n    max_depth.append(tree.tree_.max_depth)\n\nprint(f\"-----Random Forest-----\")\nprint(f\"Depth: {sum(max_depth)/len(max_depth)}\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"Number of Leaves: {num_leaves}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()\n\n\n# -----XGBoost-----\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\n\n# best_depth=3\nxgb_clf = XGBRegressor(\n    reg_lambda=0.01,\n    #max_depth=best_depth,\n    random_state=42,\n    use_label_encoder=False,\n    eval_metric=\"logloss\",\n)\n#xgb_clf = XGBClassifier(\n#    reg_lambda=0.008,\n#    #max_depth=best_depth,\n#    random_state=42,\n#    use_label_encoder=False,\n#    eval_metric=\"logloss\",\n# )\n\nstart_time = time.time()\nxgb_clf.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\n# Predict on the test set\ny_test_pred = xgb_clf.predict(X_test)\n\n# Get the number of leaves\n# num_leaves = xgb_clf.get_booster().trees_to_dataframe()[\"Tree\"].nunique()\nnum_leaves = len(xgb_clf.get_booster().trees_to_dataframe())\nnum_calc = (\n    xgb_clf.get_booster().trees_to_dataframe()[\"Node\"].nunique()\n    * xgb_clf.get_booster().trees_to_dataframe()[\"Tree\"].nunique()\n)\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\n\nprint(f\"-----XGBoost-----\")\nprint(f\"Depth: {sum(max_depth)/len(max_depth)}\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"Number of Leaves: {num_leaves}\")\nprint(f\"Number of Calcs: {num_calc}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()\n\n\n# -----SVM-----\nfrom sklearn.svm import SVR\nfrom sklearn.svm import SVC\n\n# Initialize the SVM classifier\nsvm_model = SVR()\n#svm_model = SVC()\n\nstart_time = time.time()\nsvm_model.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\n# Predict on the test set\ny_test_pred = svm_model.predict(X_test)\n\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\nnum_vectors = len(svm_model.support_vectors_)\nnum_calc = X_test.shape[0] * num_vectors\n\nprint(f\"-----SVM-----\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"# of Vectors: {num_vectors}\")\nprint(f\"# of Calculations: {num_calc}\")\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()\n\n\n# -----Perceptron-----\nfrom sklearn.linear_model import Perceptron\n\n# Initialize the Perceptron model\nperceptron = Perceptron()\n\n# Train the model\nstart_time = time.time()\n#perceptron.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\n# Test the model\n#y_test_pred = perceptron.predict(X_test)\n#y_test_pred = perceptron.predict_proba(X_test)\n\n# Calculate accuracy\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\nnum_calc = X_test.shape[0] * X_train.shape[1]\n\nprint(f\"-----Perceptron-----\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"Number of Calcs: {num_calc}\")\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()\n\n\n# -----Logistic Regression-----\nfrom sklearn.linear_model import LogisticRegression\n\n# Initialize the Perceptron model\nlog_reg = LogisticRegression(tol=0.008)\n\n# Train the model\nstart_time = time.time()\n#log_reg.fit(X_train, y_train)\nelapsed_time = time.time() - start_time\n\n# Test the model\n#y_test_pred = log_reg.predict(X_test)\n#y_test_pred = log_reg.predict_proba(X_test)\n\n# Calculate accuracy\nmse = mean_squared_error(y_test, y_test_pred)\nrmse = sqrt(mse)\nr2 = r2_score(y_test, y_test_pred)\n#acc_score = accuracy_score(y_test, y_test_pred)\n#bal_acc_score = balanced_accuracy_score(y_test, y_test_pred)\n#roc_score = roc_auc_score(y_test, y_test_pred)\nnum_calc = X_test.shape[0] * X_train.shape[1]\n\nprint(f\"-----Logistic Regression-----\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"R2: {r2}\")\n#print(f\"Accuracy: {acc_score}\")\n#print(f\"Balanced Accuracy: {bal_acc_score}\")\n#print(\"ROC AUC Score: {}\".format(roc_score))\nprint(f\"Number of Calcs: {num_calc}\")\nprint(f\"{elapsed_time:.5f}s elapsed during training\")\nprint()","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"-----CART-----\nDepth: 7\nMSE: 0.0041864795048176945\nRMSE: 0.06470301001358202\nNumber of Leaves: 8\nR2: 0.8150061894804989\n0.06850s elapsed during training\n\n-----Random Forest-----\nDepth: 6.98\nMSE: 0.004186303795168794\nRMSE: 0.06470165218268227\nNumber of Leaves: 798\nR2: 0.8150139538078908\n4.03794s elapsed during training\n\n-----XGBoost-----\nDepth: 6.98\nMSE: 0.00048596708967255255\nRMSE: 0.022044661251027484\nNumber of Leaves: 10528\nNumber of Calcs: 11900\nR2: 0.978525894226368\n7.68581s elapsed during training\n\n-----SVM-----\nMSE: 0.0038024532813058926\nRMSE: 0.06166403555806166\nR2: 0.8319756919813729\n# of Vectors: 846\n# of Calculations: 4920336\n2.08740s elapsed during training\n\n-----Perceptron-----\nMSE: 0.0038024532813058926\nRMSE: 0.06166403555806166\nR2: 0.8319756919813729\nNumber of Calcs: 552520\n0.00003s elapsed during training\n\n-----Logistic Regression-----\nMSE: 0.0038024532813058926\nRMSE: 0.06166403555806166\nR2: 0.8319756919813729\nNumber of Calcs: 552520\n0.00003s elapsed during training\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Reduce dimensions to 2D for visualization, using PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\n# Fit the model on the reduced data\nsvm_model.fit(X_pca, y)\n#perceptron.fit(X_pca, y)\n#log_reg.fit(X_pca, y)\n\n\n# Create a grid to plot decision boundaries\nh = 0.02  # step size in the mesh\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n# Predict class labels for the grid\nZ = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n#Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()])\n#Z = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot the decision boundaries\nplt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n\n# Plot also the training points\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=plt.cm.coolwarm)\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\nplt.title(\"SVM Decision Boundaries with PCA-Reduced Data\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[{"data":{"image/png":"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\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# Hyperparameter search\n\ndef hyperParameterSearch(param_grid, X_train, X_test, y_train, y_test):\n    print(param_grid)\n    best_num_leaves = 10000\n    best_r2 = 0\n    best_mse = 10000\n    best_params = []\n    best_model = None\n    for i in range(len(param_grid[\"depth_budget\"])):\n        for j in range(len(param_grid[\"regularization\"])):\n            depth_budget = param_grid[\"depth_budget\"][i]\n            regularization = param_grid[\"regularization\"][j]\n            params = {\n            \"similar_support\": False,\n            \"regularization\": regularization,\n            \"depth_budget\": depth_budget,\n            }\n\n            # Print current list of params\n            #print(\"Current params:\")\n            #print(params)\n\n            model = OSRT(params)\n            model.fit(X_train, y_train)\n\n            # get the results of trained model\n            n_leaves = model.leaves()\n            #print(\"Current # of leaves: {}\".format(n_leaves))\n\n            # Test model\n            predict = model.predict(X_test)\n            r2 = r2_score(y_test, predict)\n            mse = mean_squared_error(y_test, predict)\n            #print(\"Current R2: {}\".format(r2))\n            #print(\"Current MSE: {}\".format(mse))\n            #print()\n\n            if n_leaves <= best_num_leaves+3 and r2 > best_r2:\n                best_params = {\n                    \"depth_budget\": depth_budget,\n                    \"regularization\": regularization\n                }\n                best_mse = mse\n                best_r2 = r2\n                best_num_leaves = n_leaves\n                best_model = model\n    return best_model, best_params, best_mse, best_r2, best_num_leaves","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform K-fold validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, roc_auc_score, balanced_accuracy_score\nfrom osrt.model.threshold_guess import compute_thresholds\nfrom gosdt.model.gosdt import GOSDT\nfrom osrt.model.osrt import OSRT\n\n# read the dataset\n# preprocess your data otherwise OSRT will binarize continuous feature using all threshold values.\ndf = pd.read_csv(\"significant_variables3.csv\")\nX, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\nh = df.columns[:-1]\nX = pd.DataFrame(X, columns=h)\n\n# guess thresholds (OPTIONAL) uncomment following lines if you want to speed up optimization\n# NOTE: You should also evaluate accuracy on guessed data if you choose to guess thresholds\n# GBRT parameters for threshold guesses\nn_est = 40\nmax_depth = 1\nX_opt, thresholds, header, threshold_guess_time = compute_thresholds(\n    X, y, n_est, max_depth\n)\n\n\n# K Fold validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n\nregularization_list = [0.0001,0.0005,0.001,0.005,0.01]\n\nfor regularization in regularization_list:\n    list_mse = []\n    list_leaves = []\n    list_r2 = []\n    list_depth = []\n    results = []\n    for train_index, test_index in kf.split(X_opt):\n        X_train_kf, X_test_kf = X_opt.iloc[train_index], X_opt.iloc[test_index]\n        y_train_kf, y_test_kf = y[train_index], y[test_index]\n\n        config = {\n            \"similar_support\": False,\n            \"regularization\": regularization,\n        }\n\n        model = GOSDT(config)\n        #model = OSRT(config)\n        model.fit(X_train_kf, y_train_kf)\n        y_test_pred_kf = model.predict(X_test_kf)\n\n        mse = mean_squared_error(y_test_kf, y_test_pred_kf)\n        leaves = model.leaves()\n        #r2 = accuracy_score(y_test_kf, y_test_pred_kf)\n        r2 = r2_score(y_test_kf, y_test_pred_kf)\n        depth = model.max_depth()\n        list_mse.append(mse)\n        list_leaves.append(leaves)\n        list_r2.append(r2)\n        list_depth.append(depth)\n\n    avg_mse = np.mean(list_mse)\n    avg_leaves = np.mean(list_leaves)\n    avg_r2 = np.mean(list_r2)\n    avg_depth = np.mean(list_depth)\n    results.append(\n        {\n            \"avg_depth\": avg_depth,\n            \"avg_mse\": avg_mse,\n            \"avg_leaves\": avg_leaves,\n            \"avg_r2\": avg_r2\n        }\n    )\n\n    # Display the results\n    for result in results:\n        print(f\"Regularization: {regularization}\")\n        print(f\"Average Depth: {result['avg_depth']}\")\n        print(f\"Average MSE: {result['avg_mse']}\")\n        print(f\"Average Number of Leaves: {result['avg_leaves']}\")\n        print(f\"Average R2: {result['avg_r2']}\")\n        print(f\"Accuracy: {acc_score}\")\n        print(f\"Balanced Accuracy: {bal_acc_score}\")\n        print(\"ROC AUC Score: {}\".format(roc_score))\n        print(model.tree)\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"gosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\nRegularization: 0.0001\nAverage Depth: 3.0\nAverage MSE: 0.0\nAverage Number of Leaves: 3.0\nAverage R2: 1.0\nAccuracy: 0.9936305732484076\nBalanced Accuracy: 0.9958677685950413\nROC AUC Score: 0.9958677685950413\nif anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 = 1 then:\n    predicted class: 1\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\nRegularization: 0.0005\nAverage Depth: 3.0\nAverage MSE: 0.0\nAverage Number of Leaves: 3.0\nAverage R2: 1.0\nAccuracy: 0.9936305732484076\nBalanced Accuracy: 0.9958677685950413\nROC AUC Score: 0.9958677685950413\nif anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 = 1 then:\n    predicted class: 1\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004792..0.004792] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.004785..0.004785] (0.000000) loss=0.000000, iterations=26\nRegularization: 0.001\nAverage Depth: 3.0\nAverage MSE: 0.0\nAverage Number of Leaves: 3.0\nAverage R2: 1.0\nAccuracy: 0.9936305732484076\nBalanced Accuracy: 0.9958677685950413\nROC AUC Score: 0.9958677685950413\nif anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 = 1 then:\n    predicted class: 1\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\n\nelse if anxiousness_False<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.002\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.015000..0.015000] (0.000000) loss=0.000000, iterations=9\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.015000..0.015000] (0.000000) loss=0.000000, iterations=9\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.015000..0.015000] (0.000000) loss=0.000000, iterations=9\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.015000..0.015000] (0.000000) loss=0.000000, iterations=9\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.015000..0.015000] (0.000000) loss=0.000000, iterations=9\nRegularization: 0.005\nAverage Depth: 3.0\nAverage MSE: 0.0\nAverage Number of Leaves: 3.0\nAverage R2: 1.0\nAccuracy: 0.9936305732484076\nBalanced Accuracy: 0.9958677685950413\nROC AUC Score: 0.9958677685950413\nif anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 = 1 then:\n    predicted class: 1\n    misclassification penalty: 0.0\n    complexity penalty: 0.005\n\nelse if anxiousness_False<=0.5 = 1 and gad_score_1<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.005\n\nelse if anxiousness_False<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.005\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.026390..0.026390] (0.000000) loss=0.006390, iterations=0\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.026390..0.026390] (0.000000) loss=0.006390, iterations=0\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.027987..0.027987] (0.000000) loss=0.007987, iterations=0\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.027974..0.027974] (0.000000) loss=0.007974, iterations=0\ngosdt reported successful execution\ntraining completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\nbounds: [0.029569..0.029569] (0.000000) loss=0.009569, iterations=0\nRegularization: 0.01\nAverage Depth: 2.0\nAverage MSE: 0.007651478033643638\nAverage Number of Leaves: 2.0\nAverage R2: 0.9584294899430652\nAccuracy: 0.9936305732484076\nBalanced Accuracy: 0.9958677685950413\nROC AUC Score: 0.9958677685950413\nif anxiousness_False<=0.5 = 1 then:\n    predicted class: 1\n    misclassification penalty: 0.01\n    complexity penalty: 0.01\n\nelse if anxiousness_False<=0.5 != 1 then:\n    predicted class: 0\n    misclassification penalty: 0.0\n    complexity penalty: 0.01\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"correlation_matrix = df.corr()\ncorrelation_matrix\nplt.figure(figsize=(12, 10))\nplt.title(\"Heatmap of Correlation Matrix\")\nsns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nplt.show()\n\nplt.figure(figsize=(12, 10))\nplt.title(\"Heatmap of Correlation Matrix\")\nsns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nplt.savefig(\"correlation_matrix_heatmap.png\")\nplt.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n\n# Create a DataFrame from the provided data\nalgorithm_data = {\n    \"Algorithm\": [\"GOSDT\", \"CART\", \"Random Forest\", \"XGBoost\"],\n    \"Test Accuracy\": [0.805, 0.805, 0.820, 0.966],\n    \"ROC Score\": [0.804, 0.805, 0.819, 0.956],\n    \"Training Time (secs)\": [0.015, 0.003, 0.168, 0.158],\n    \"# of Leaves\": [6, 8, 655, 3064],\n    \"Average Depth per Tree\": [4, 4, 4, 4],\n}\ndf = pd.DataFrame(algorithm_data)\n\n# Define colors\npestle_colors = [\"#6A5ACD\", \"#FF69B4\", \"#20B2AA\", \"#778899\"]\n\n# Function to save pie chart\ndef save_pie_chart(data, labels, title, filename):\n    fig, ax = plt.subplots()\n    ax.pie(\n        data,\n        labels=labels,\n        autopct=\"%1.1f%%\",\n        startangle=140,\n        colors=pestle_colors,\n    )\n    ax.set_title(title)\n    plt.tight_layout()\n    plt.savefig(filename)\n    plt.close()\n\n\n# Replace 'GOSDT' with 'OST' in the labels\nlabels = df[\"Algorithm\"].replace(\"GOSDT\", \"OST\")\n\n# Test Accuracy\nsave_pie_chart(\n    df[\"Test Accuracy\"], labels, \"Test Accuracy\", \"test_accuracy_pie_chart.png\"\n)\n\n# ROC Score\nsave_pie_chart(df[\"ROC Score\"], labels, \"ROC Score\", \"roc_score_pie_chart.png\")\n\n# Training Time\nsave_pie_chart(\n    df[\"Training Time (secs)\"], labels, \"Training Time\", \"training_time_pie_chart.png\"\n)\n\n# Number of Leaves\nsave_pie_chart(\n    df[\"# of Leaves\"], labels, \"Number of Leaves\", \"number_of_leaves_pie_chart.png\"\n)","metadata":{},"execution_count":null,"outputs":[]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":"CALEB RODRIGUEZ","project_id":"263929f6-ea30-49a4-86d2-7f4b5708720d","version":"import","exported_date":"Sun Apr 21 2024 20:55:18 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}